{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Generative AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(model=None, u_question=None):\n",
    "    prompt_template = \"\"\"\n",
    "        Answer the question as detailed as possible.\n",
    "            Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    \n",
    "    if model == \"open-ai\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        llm = ChatOpenAI(api_key=api_key)\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"question\"])\n",
    "        llm_chain = prompt | llm\n",
    "        response = llm_chain.invoke({'question':u_question})\n",
    "        return response\n",
    "    elif model == \"gemini-pro\":\n",
    "\n",
    "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro\", \n",
    "        temperature=0.3,\n",
    "        google_api_key=api_key,     \n",
    "        safety_settings={ \n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        },)\n",
    "        \n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[ \"question\"])\n",
    "        llm_chain = prompt | llm\n",
    "        response = llm_chain.invoke({'question':u_question})\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    question = \"\"\"How can AI and machine learning be integrated into \n",
    "    microservices architecture to improve scalability and reliability in telecom systems?\n",
    "    \"\"\"\n",
    "\n",
    "    response = main(model=\"gemini-pro\", u_question=question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Integration of AI and Machine Learning into Microservices Architecture for Enhanced Scalability and Reliability in Telecom Systems**\\n\\n**Introduction**\\n\\nMicroservices architecture has emerged as a preferred approach for designing and developing telecom systems due to its flexibility, scalability, and maintainability. By decomposing complex systems into smaller, independent services, microservices architecture enables faster development, easier deployment, and improved fault tolerance. However, as telecom systems grow in size and complexity, ensuring scalability and reliability becomes increasingly challenging.\\n\\nArtificial intelligence (AI) and machine learning (ML) offer powerful techniques for addressing these challenges. By leveraging AI and ML algorithms, telecom systems can automate tasks, optimize resource allocation, and predict and prevent failures. Integrating AI and ML into microservices architecture can significantly enhance the scalability and reliability of telecom systems.\\n\\n**Benefits of Integrating AI and ML into Microservices Architecture**\\n\\n* **Improved Scalability:** AI and ML algorithms can dynamically adjust resource allocation based on real-time demand, ensuring optimal performance even under fluctuating workloads.\\n* **Enhanced Reliability:** ML models can predict and prevent failures by identifying patterns and anomalies in system behavior. This proactive approach reduces downtime and improves service availability.\\n* **Automated Operations:** AI-powered tools can automate tasks such as service discovery, load balancing, and self-healing, reducing operational overhead and improving efficiency.\\n* **Optimized Performance:** ML algorithms can analyze system metrics and identify performance bottlenecks, enabling targeted optimizations to improve overall system performance.\\n* **Enhanced Security:** AI and ML techniques can be used to detect and mitigate security threats, protecting telecom systems from cyberattacks and data breaches.\\n\\n**Integration Strategies**\\n\\nThere are several strategies for integrating AI and ML into microservices architecture:\\n\\n* **Centralized AI/ML Services:** Create a dedicated AI/ML service that provides AI and ML capabilities to all microservices. This approach simplifies integration but may introduce performance bottlenecks.\\n* **Decentralized AI/ML Modules:** Embed AI/ML modules directly into individual microservices. This approach provides greater flexibility and scalability but requires more development effort.\\n* **Hybrid Approach:** Combine centralized and decentralized approaches, providing a balance between flexibility and performance.\\n\\n**Use Cases**\\n\\n* **Dynamic Resource Allocation:** AI algorithms can analyze traffic patterns and predict future demand, enabling dynamic allocation of resources to meet fluctuating workloads.\\n* **Predictive Maintenance:** ML models can analyze system logs and metrics to identify potential failures before they occur, allowing for proactive maintenance and reduced downtime.\\n* **Automated Fault Detection and Recovery:** AI-powered tools can monitor system behavior and automatically detect and recover from failures, minimizing service disruptions.\\n* **Network Optimization:** ML algorithms can analyze network data to identify and resolve performance bottlenecks, improving network efficiency and reducing latency.\\n* **Fraud Detection:** AI and ML techniques can be used to detect and prevent fraudulent activities, protecting telecom systems from financial losses.\\n\\n**Conclusion**\\n\\nIntegrating AI and ML into microservices architecture offers significant benefits for improving the scalability and reliability of telecom systems. By leveraging AI and ML algorithms, telecom systems can automate tasks, optimize resource allocation, predict and prevent failures, and enhance overall system performance. As AI and ML technologies continue to advance, their integration into microservices architecture will play a crucial role in enabling the next generation of highly scalable and reliable telecom systems.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"I want to develop a redlight area suggest some fancy name for this . it is just a business you can suggest me name\"\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\", \n",
    "    temperature=1,\n",
    "    google_api_key=api_key,\n",
    "    safety_settings={ \n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "\n",
    "\n",
    "response = llm.invoke(input=prompt_template)  # Pass the prompt as input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to develop a area51 suggest some fancy name for this . it is just a business you can suggest me name'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(input_variables=['area'],\n",
    "                                     template=\"I want to develop a {area} suggest some fancy name for this . it is just a business you can suggest me name\"\n",
    ")\n",
    "prompt_template_name.format(area=\"area51\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': 'area51',\n",
       " 'text': '**Celestial Enigmas**\\n**Ethereal Expanse**\\n**Beyond the Veil**\\n**Intergalactic Nexus**\\n**Unveiled Secrets**\\n**Cosmic Confluence**\\n**Galactic Gateway**\\n**Enigma Corp**\\n**Astral Convergence**\\n**Celestial Enigma**\\n**Ethereal Horizons**\\n**Unveiled Mysteries**\\n**Beyond the Unknown**\\n**Interstellar Intelligence**\\n**Cosmic Odyssey**\\n**Enigma Industries**\\n**Astral Insights**\\n**Celestial Horizons**\\n**Ethereal Nexus**\\n**Unveiled Enigma**\\n**Beyond the Beyond**\\n**Interstellar Explorations**\\n**Cosmic Conundrum**'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "chain.invoke(\"area51\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'samosa',\n",
       " 'text': '**Savory Samosa Delights**\\n**Samosa Haven**\\n**Golden Samosa Emporium**\\n**Spice & Samosa**\\n**Crispy Corner**\\n**Samosa Palace**\\n**Samosa Central**\\n**Samosa Junction**\\n**Taste of India: Samosas**\\n**The Samosa Saga**\\n**Samosa Paradise**\\n**The Samosa Station**\\n**Samosa Supreme**\\n**Samosa Bistro**\\n**Samosa Corner**\\n**Samosa Express**'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential chain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\", \n",
    "    temperature=1,\n",
    "    google_api_key=api_key,\n",
    "    safety_settings={ \n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "prompt_template_name = PromptTemplate(input_variables=['cuisine'],\n",
    "                                      template=\"I want to develop a {cuisine}. suggest a restaurant name\")\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name_chain.invoke(\"samosa\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"suggest some menu items for {restaurant_name}.Return it as a comma seperated\"\n",
    ")\n",
    "food_items_chain=LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'restaurant_name': 'savory samosa delights',\n",
       " 'text': 'Lamb Keema, Paneer Tikka, Mixed Vegetable, Chicken Makhani, Mushroom and Cheese, Potato and Peas'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_items_chain.invoke(\"savory samosa delights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain=SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
    "response=chain.invoke(\"mEXICAN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Traditional Mexican**\n",
      "- El Sabor de México\n",
      "- Mi Casa Mexicana\n",
      "- Hacienda Mexicana\n",
      "- La Cantina del Sur\n",
      "- Rancho Grande\n",
      "\n",
      "**Modern Mexican**\n",
      "- Mezcla Mexicana\n",
      "- Frontera Fresca\n",
      "- El Mercado\n",
      "- Taco Revolution\n",
      "- Masa y Fuego\n",
      "\n",
      "**Taqueria-Inspired**\n",
      "- Taqueria El Toro\n",
      "- Los Tacos Auténticos\n",
      "- La Taqueria Caliente\n",
      "- Taquería La Lupita\n",
      "- El Rey de los Tacos\n",
      "\n",
      "**Regional Mexican**\n",
      "- Oaxacalifornia\n",
      "- Yucatan Kitchen\n",
      "- Los Sabores de Puebla\n",
      "- Jalisco Taqueria\n",
      "- Chihuahua Grill\n",
      "\n",
      "**Fine-Dining Mexican**\n",
      "- Hacienda de los Santos\n",
      "- El Cielo\n",
      "- Quintonil\n",
      "- Biko\n",
      "- Pujol\n",
      "\n",
      "**Whimsical Mexican**\n",
      "- El Burro Loco\n",
      "- El Sombrero Cantina\n",
      "- La Fiesta Mexicana\n",
      "- Mamacita's Restaurant\n",
      "- El Chingón\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential chain\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\", \n",
    "    temperature=1,\n",
    "    google_api_key=api_key,\n",
    "    safety_settings={ \n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "prompt_template_name = PromptTemplate(input_variables=['cuisine'],\n",
    "                                      template=\"I want to open a restaurant for  a {cuisine}. suggest a restaurant name\")\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key='restaurant_name')\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\", \n",
    "    temperature=1,\n",
    "    google_api_key=api_key,\n",
    "    safety_settings={ \n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    },)\n",
    "prompt_template_items=PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"suggest some menu items for {restaurant_name}. Return it as a comma seperated\"\n",
    ")\n",
    "\n",
    "food_items_chain=LLMChain(llm=llm,prompt=prompt_template_items,output_key=\"menu_items\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain=SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"restaurant_name\",'menu_items']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '**Elegant and Sophisticated:**\\n\\n* Al Shams (The Sun)\\n* Al Noor (The Light)\\n* Qamar (The Moon)\\n* Al Saraya (The Palace)\\n* Dar Al Teeba (House of the Good)\\n\\n**Evocative and Cultural:**\\n\\n* Maqam Al Shami (Seat of the Levant)\\n* Beit Al Zahra (House of the Flower)\\n* Majlis Al Mirbad (Gathering Place of the Wise)\\n* Souq Al Athar (Market of Antiquities)\\n* Khayal Al Shams (Vision of the Sun)\\n\\n**Traditional and Rustic:**\\n\\n* Beit Al Arab (Arabian House)\\n* Al Qahwa (The Coffee House)\\n* Al Manzil (The Dwelling)\\n* Al Mafraj (The Sanctuary)\\n* Al Majlis (The Assembly)\\n\\n**Poetic and Inspiring:**\\n\\n* Al Ardha (The Dance)\\n* Shams Al Andalus (Sun of Andalusia)\\n* Nadhir Al Layl (Dawn of the Night)\\n* Qalb Al Sharq (Heart of the East)\\n* Shams Al Tareef (Sun of Glory)\\n\\n**Modern and Contemporary:**\\n\\n* Urban Tajine\\n* Middle Eastern Bistro\\n* Arabesque Flavors\\n* Saffron & Spice\\n* The Levant Kitchen',\n",
       " 'menu_items': 'Al Shams, Al Noor, Qamar, Al Saraya, Dar Al Teeba, Maqam Al Shami, Beit Al Zahra, Majlis Al Mirbad, Souq Al Athar, Khayal Al Shams, Beit Al Arab, Al Qahwa, Al Manzil, Al Mafraj, Al Majlis, Al Ardha, Shams Al Andalus, Nadhir Al Layl, Qalb Al Sharq, Shams Al Tareef, Urban Tajine, Middle Eastern Bistro, Arabesque Flavors, Saffron & Spice, The Levant Kitchen'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(({'cuisine':\"Arabic\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
